
# ğŸ“˜ PrÃ©traitement et PrÃ©paration du Dataset NSL-KDD pour la DÃ©tection d'Anomalies

## ğŸ¯ Objectif
Transformer le dataset brut NSL-KDD en un format exploitable pour entraÃ®ner un modÃ¨le de Machine Learning, comme une ForÃªt AlÃ©atoire (Random Forest), pour dÃ©tecter des comportements anormaux dans le trafic rÃ©seau.

---

## 1. ğŸ” Classification Binaire

**But :** Distinguer le trafic *normal* du trafic *anormal (attaque)*.

```python
df['attack_flag'] = df['attack'].apply(lambda a: 0 if a == 'normal' else 1)
```

> `attack_flag = 0` âŸ¶ trafic normal  
> `attack_flag = 1` âŸ¶ attaque

---

## 2. ğŸŒˆ Classification Multi-Classes

**But :** Identifier le *type* dâ€™attaque parmi 4 catÃ©gories :

| Classe | Type dâ€™attaque                 |
|--------|-------------------------------|
| 0      | Normal                         |
| 1      | DoS (Denial of Service)       |
| 2      | Probe (Scan de rÃ©seau)        |
| 3      | Privilege Escalation          |
| 4      | Access (Violation accÃ¨s)      |

Extrait :
```python
df['attack_map'] = df['attack'].apply(map_attack)
```

---

## 3. ğŸ”  Encodage des variables catÃ©gorielles

Certaines colonnes comme `protocol_type` ou `service` sont des textes (`tcp`, `http`, etc.).

ğŸ”§ On les transforme avec **one-hot encoding** :

```python
encoded = pd.get_dummies(df[['protocol_type', 'service']])
```

> Cela crÃ©e une colonne binaire pour chaque valeur unique (ex: `protocol_type_tcp`, `protocol_type_udp`, etc.)

---

## 4. ğŸ”¢ SÃ©lection des Features NumÃ©riques

Ce sont des indicateurs statistiques sur le trafic (durÃ©e, octets Ã©changÃ©s, taux dâ€™erreurs, etc.).

```python
numeric_features = ['duration', 'src_bytes', 'dst_bytes', ..., 'dst_host_srv_rerror_rate']
```

---

## 5. ğŸ”— Assemblage du dataset

On **combine** les donnÃ©es encodÃ©es et les features numÃ©riques pour obtenir un dataset complet prÃªt Ã  l'entraÃ®nement.

```python
train_set = encoded.join(df[numeric_features])
multi_y = df['attack_map']
```

---

## 6. âœ‚ï¸ Split : EntraÃ®nement / Test / Validation

On sÃ©pare les donnÃ©es en 3 sous-ensembles :

| Ensemble     | RÃ´le                           |
|--------------|--------------------------------|
| `train`      | Apprentissage du modÃ¨le        |
| `val`        | RÃ©glage des hyperparamÃ¨tres    |
| `test`       | Ã‰valuation finale              |

Extrait :

```python
train_X, test_X, train_y, test_y = train_test_split(...)
multi_train_X, multi_val_X, multi_train_y, multi_val_y = train_test_split(...)
```

---

## ğŸ§  En rÃ©sumÃ©

| Ã‰tape                        | Objectif                               |
|-----------------------------|----------------------------------------|
| Binaire & Multi-Classe      | CrÃ©er des cibles                       |
| Encodage catÃ©goriel         | Transformer les textes en chiffres     |
| SÃ©lection de features       | Garder les colonnes utiles             |
| Fusion donnÃ©es              | CrÃ©er un DataFrame exploitable         |
| DÃ©coupage                   | Ã‰valuer correctement le modÃ¨le         |

> âœ… PrÃªt pour entraÃ®ner un modÃ¨le de dÃ©tection (Random Forest, etc.)

---

## âœï¸ Auteur
Formation HTB Academy â€“ AdaptÃ© pour `IT_Formation`

