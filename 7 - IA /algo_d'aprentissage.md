# ğŸ¤– Algorithmes dâ€™Apprentissage SupervisÃ©

L'apprentissage supervisÃ© est au cÅ“ur de nombreuses applications en machine learning (ML). Il repose sur l'utilisation de **donnÃ©es Ã©tiquetÃ©es** pour entraÃ®ner un modÃ¨le capable de **prÃ©dire** des rÃ©sultats sur de nouvelles donnÃ©es.

---

## ğŸ§  Principe gÃ©nÃ©ral

Lâ€™objectif est dâ€™**apprendre une fonction de cartographie** entre des variables dâ€™entrÃ©e (features) et des rÃ©sultats attendus (labels).

Exemple : montrer Ã  un enfant une **pomme** et une **orange** avec leurs noms. Ã€ force dâ€™observation, il apprend Ã  les reconnaÃ®tre par leurs **caractÃ©ristiques** (couleur, forme, taille).

---

## ğŸ§ª Types de problÃ¨mes

- **Classification** : prÃ©dire une **catÃ©gorie** (ex. : spam / non spam)
- **RÃ©gression** : prÃ©dire une **valeur continue** (ex. : prix dâ€™une maison)

---

## ğŸ§± Concepts clÃ©s

### ğŸ“Š DonnÃ©es de formation (Training Data)
Ensemble Ã©tiquetÃ© utilisÃ© pour apprendre. La qualitÃ© et la quantitÃ© ont un **impact direct** sur les performances.

### ğŸ§© CaractÃ©ristiques (Features)
Variables d'entrÃ©e (taille, localisation, Ã¢ge d'une maison, etc.)

### ğŸ¯ Ã‰tiquettes (Labels)
RÃ©sultats attendus (ex. : prix de la maison)

### ğŸ§® ModÃ¨le (Model)
Fonction mathÃ©matique apprenant Ã  partir des donnÃ©es.

### ğŸ—ï¸ EntraÃ®nement (Training)
Phase oÃ¹ lâ€™algorithme ajuste ses paramÃ¨tres pour **minimiser lâ€™erreur** de prÃ©diction.

### ğŸ” PrÃ©diction (Prediction)
Utilisation du modÃ¨le sur de **nouvelles donnÃ©es** pour prÃ©dire lâ€™Ã©tiquette.

### ğŸ§  InfÃ©rence (Inference)
Comprendre les **relations internes** du modÃ¨le : importance des features, structure de la dÃ©cision, etc.

---

## ğŸ§ª Ã‰valuation du modÃ¨le

| ğŸ“ Mesure       | Description |
|----------------|-------------|
| **Accuracy**    | Proportion de prÃ©dictions correctes |
| **Precision**   | % de vraies positives parmi les prÃ©dictions positives |
| **Recall**      | % de vraies positives parmi toutes les positives rÃ©elles |
| **F1-score**    | Moyenne harmonique entre precision et recall |

---

## ğŸ§¬ CapacitÃ© de gÃ©nÃ©ralisation

- **GÃ©nÃ©ralisation** : bonne capacitÃ© Ã  prÃ©dire sur des **donnÃ©es inconnues**.
- **Overfitting (surapprentissage)** : le modÃ¨le **mÃ©morise** trop les donnÃ©es d'entraÃ®nement.
- **Underfitting (sous-apprentissage)** : le modÃ¨le est trop **simple** pour capturer les schÃ©mas.

---

## ğŸ”„ Techniques avancÃ©es

### âœ… Validation croisÃ©e (Cross-Validation)
Diviser les donnÃ©es en **k sous-ensembles** pour tester la robustesse du modÃ¨le.

### ğŸ“‰ RÃ©gularisation (Regularization)
RÃ©duire le surajustement en **pÃ©nalisant la complexitÃ©** du modÃ¨le.

- **L1 (Lasso)** : pÃ©nalise la somme des valeurs absolues des coefficients
- **L2 (Ridge)** : pÃ©nalise la somme des carrÃ©s des coefficients

---

## ğŸ“Œ RÃ©sumÃ©

L'apprentissage supervisÃ© permet aux machines dâ€™**apprendre Ã  partir dâ€™exemples**. Câ€™est un pilier du ML appliquÃ© Ã  :
- La dÃ©tection de fraude
- La reconnaissance dâ€™images
- Les prÃ©visions financiÃ¨res
- Le traitement des emails (spam)

ğŸ‘‰ MaÃ®triser ces bases est essentiel avant dâ€™aborder les modÃ¨les plus complexes comme les rÃ©seaux de neurones ou les LLM.

---

